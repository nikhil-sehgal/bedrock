# Security Risks in Generative AI ðŸ”’

Generative AI unlocks creativity, but it also introduces unique security concerns.

### Key Risks
1. **Data Leakage** â†’ Sensitive data in prompts could be exposed.
2. **Hallucinations** â†’ Models generate false but convincing outputs.
3. **Prompt Injection** â†’ Attackers manipulate model instructions.
4. **Model Bias** â†’ LLMs may amplify social or cultural biases.
5. **Malicious Use** â†’ Deepfakes, spam, misinformation.

### Mitigation Strategies
- Use **guardrails** (Bedrock Guardrails, Azure Safety, OpenAI moderation).
- **Filter inputs and outputs** to block harmful text.
- Keep **human-in-the-loop** for critical decisions.
- Monitor **usage logs** for anomalies.

### Final Take
Security is not optional. GenAI adoption must include robust guardrails and compliance checks.
